{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-FunctionMinimization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "_5o1S6yXrpeR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# <center>Function Minimization</center>\n",
        "## <center>Starting With Empty Model</center>\n",
        "### <center>Dr David Race</center>"
      ]
    },
    {
      "metadata": {
        "id": "if8FECnSr8TW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook is specifically designed to use the Deep Learning toolkit (pytorch) to determine the minimum of a non-negative convex function.  The input will be a \"loss\" function and a starting point, then it finds the location and value of the minimum of the function."
      ]
    },
    {
      "metadata": {
        "id": "5lFCXIzDskcw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set Up Environment"
      ]
    },
    {
      "metadata": {
        "id": "U14UhNEbs8jn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This section installs the basic pytorch capabilities into the Colaboratory VM."
      ]
    },
    {
      "metadata": {
        "id": "zt7FWfbCtZP3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "!pip3 --version\n",
        "!pip3 install -U torch torchvision\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vOA2CK4Sriam",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from pprint import pprint, pformat\n",
        "pprint(accelerator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zEUVPatZzZtf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example 1 - $x^2 + y^2 + 4$"
      ]
    },
    {
      "metadata": {
        "id": "43X0AtraznP3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this example, we will compute the minimum of $x^2 + y + 4^2$ starting at a random point.  The point will be initialized using randn."
      ]
    },
    {
      "metadata": {
        "id": "Bb3iE8MWziCz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define setup\n",
        "offset = torch.Tensor([4.], device = device).double()\n",
        "mean_val = 10.\n",
        "std_val = 20.\n",
        "iter_stop = 1e-7\n",
        "max_iter = 100\n",
        "def compute_loss_error(l1, l2):\n",
        "  return np.abs(l1 - l2)/np.max([l1,l2])\n",
        "\n",
        "def loss_f(in_pos):\n",
        "  y = in_pos.pow(2).sum() + offset\n",
        "  return y\n",
        "  \n",
        "device = torch.device(accelerator)\n",
        "np.random.seed(0)\n",
        "N = 2\n",
        "x1 = torch.Tensor(std_val * (np.random.randn(1,N) + mean_val),device=device).double()\n",
        "x1.requires_grad = True\n",
        "print(\"x1\")\n",
        "print(x1.data.numpy()[0])\n",
        "print(\"grad of x1\")\n",
        "print([2.0 * x1.data.numpy()[0][0], 2.0 * x1.data.numpy()[0][1]])\n",
        "y = loss_f(x1)\n",
        "#Optimize Using Gradient Descent\n",
        "learning_rate = .1\n",
        "i = 1\n",
        "last_loss = loss_f(x1).data.numpy()[0]\n",
        "adj_error = last_loss\n",
        "while i<=max_iter and adj_error > iter_stop:\n",
        "  loss = loss_f(x1)\n",
        "  loss.backward()\n",
        "  if(i == 1):\n",
        "    print(\"Computed Gradient\")\n",
        "    print(x1.grad.numpy()[0])\n",
        "  with torch.no_grad():\n",
        "    x1 -= learning_rate * x1.grad\n",
        "    x1.grad.zero_()\n",
        "  if i % 10 == 0:  \n",
        "    curr_loss = loss_f(x1).data.numpy()[0]\n",
        "    adj_error = compute_loss_error(last_loss,curr_loss)\n",
        "    last_loss = curr_loss\n",
        "  i = i + 1\n",
        "    \n",
        "print(\"Iteration \" + str(i))\n",
        "print(\"Approx location\")\n",
        "print(x1.data.numpy()[0])\n",
        "pprint(\"Approx Value\")\n",
        "pprint(loss_f(x1).data.numpy()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "83ytPMsG3HNt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You should note that the DL computation for the gradient is the same as the mathematical computation for the gradient.  This gradient is used throughout DL for training, so it is important to know that it is the same as the mathematical expectations."
      ]
    },
    {
      "metadata": {
        "id": "8fjcaPwhSm7c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2 - Example 1 using Stochastic Gradient Descent\n",
        "\n",
        "This method provides the same steps as the previous example, but the application of the gradient descent is carried out automatically by torch.optim.SGD().step().  The torch environment manages the application of the loss to the tensors to change within its framework (this is very handy for processing concepts.)"
      ]
    },
    {
      "metadata": {
        "id": "SYqoaFJ0Tgyw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define setup\n",
        "offset = torch.Tensor([4.]).double()\n",
        "mean_val = 10.\n",
        "std_val = 20.\n",
        "iter_stop = 1e-7\n",
        "max_iter = 1000\n",
        "def compute_loss_error(l1, l2):\n",
        "  return np.abs(l1 - l2)/np.max([l1,l2])\n",
        "\n",
        "def loss_f(in_pos):\n",
        "  y = in_pos.pow(2).sum() + offset\n",
        "  return y\n",
        "  \n",
        "device = torch.device(accelerator)\n",
        "N = 2\n",
        "#reset the seed so the results are consistent\n",
        "#\n",
        "np.random.seed(0)\n",
        "x1 = torch.Tensor(std_val * (np.random.randn(1,N) + mean_val),device=device).double()\n",
        "x1.requires_grad = True\n",
        "y = loss_f(x1)\n",
        "#define optimizer\n",
        "optimizer = torch.optim.SGD([x1], lr=.1)\n",
        "#Optimize\n",
        "i = 1\n",
        "last_loss = loss_f(x1).data.numpy()[0]\n",
        "adj_error = last_loss\n",
        "while i<=max_iter and adj_error > iter_stop:\n",
        "  optimizer.zero_grad()\n",
        "  loss = loss_f(x1)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if i % 10 == 0:  \n",
        "    curr_loss = loss_f(x1).data.numpy()[0]\n",
        "    adj_error = compute_loss_error(last_loss,curr_loss)\n",
        "    last_loss = curr_loss\n",
        "  i = i + 1\n",
        "    \n",
        "print(\"Iteration \" + str(i))\n",
        "print(\"Approx location\")\n",
        "print(x1.data.numpy()[0])\n",
        "pprint(\"Approx Value\")\n",
        "pprint(loss_f(x1).data.numpy()[0])\n",
        "print('max relative difference')\n",
        "pprint(np.abs(x1.data.numpy()[0][0] - x1.data.numpy()[0][1])/np.min(np.abs(x1.data.numpy()[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jtP13nwqTyP5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Happily, the results turn out exactly the same."
      ]
    },
    {
      "metadata": {
        "id": "nX6sRUdFE7Ly",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example 3 - Example 1 using Adam Optimizer\n",
        "\n",
        "The Adam optimizer chooses a slightly different application of the step size based upon the momentum method.  This method is very useful in machine learning, but can be applied in our simple examples using larger learning rates.  This is performed in the following compute cell.  <i>(Normally there is some experimentation to find the correct learning rate, but this notebook starts using 4.0.)</i>"
      ]
    },
    {
      "metadata": {
        "id": "Fj9nwQuqFJq-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define setup\n",
        "offset = torch.Tensor([4.]).double()\n",
        "mean_val = 10.\n",
        "std_val = 20.\n",
        "iter_stop = 1e-7\n",
        "max_iter = 1000\n",
        "def compute_loss_error(l1, l2):\n",
        "  return np.abs(l1 - l2)/np.max([l1,l2])\n",
        "\n",
        "def loss_f(in_pos):\n",
        "  y = in_pos.pow(2).sum() + offset\n",
        "  return y\n",
        "  \n",
        "device = torch.device(accelerator)\n",
        "N = 2\n",
        "np.random.seed(0)\n",
        "x1 = torch.Tensor(std_val * (np.random.randn(1,N) + mean_val),device=device).double()\n",
        "x1.requires_grad = True\n",
        "y = loss_f(x1)\n",
        "#define optimizer\n",
        "optimizer = torch.optim.Adam([x1], lr=4., betas=(.5,.9))\n",
        "#Optimize\n",
        "i = 1\n",
        "last_loss = loss_f(x1).data.numpy()[0]\n",
        "adj_error = last_loss\n",
        "while i<=max_iter and adj_error > iter_stop:\n",
        "  optimizer.zero_grad()\n",
        "  loss = loss_f(x1)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if i % 10 == 0:  \n",
        "    curr_loss = loss_f(x1).data.numpy()[0]\n",
        "    adj_error = compute_loss_error(last_loss,curr_loss)\n",
        "    last_loss = curr_loss\n",
        "  i = i + 1\n",
        "    \n",
        "print(\"Iteration \" + str(i))\n",
        "print(\"Approx location\")\n",
        "print(x1.data.numpy()[0])\n",
        "pprint(\"Approx Value\")\n",
        "pprint(loss_f(x1).data.numpy()[0])\n",
        "print('max relative difference')\n",
        "pprint(np.abs(x1.data.numpy()[0][0] - x1.data.numpy()[0][1])/np.min(np.abs(x1.data.numpy()[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tb8kuD7FVaCw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Adam optimizer is much better when there are large numbers of variables (such as with Deep Learning), but this example shows that the tools within the \"torch\" toolkit work as we expect them to in computational environments."
      ]
    },
    {
      "metadata": {
        "id": "X4dkLF_9Vw7V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example 4 - Similar to Example 1, but using $w^6 + x^6 + y^6 + z^6 + 4$"
      ]
    },
    {
      "metadata": {
        "id": "K6EOP-ezXJOl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To demonstrate that the problem complexity matters for the gradient method of choice we use the function $w^6 + x^6 + y^6 + z^6 + 4$.  In the following few cells we use the SGD and Adam to study the general capabilities."
      ]
    },
    {
      "metadata": {
        "id": "J7mv_Q-O2Bhn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Gradient Descent"
      ]
    },
    {
      "metadata": {
        "id": "a235xuqyWGXI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define setup\n",
        "from torch.autograd import Variable\n",
        "offset = Variable(torch.Tensor([4.]).double(), requires_grad = False)\n",
        "mean_val = 2.0\n",
        "std_val = 2.0\n",
        "iter_stop = 1e-7\n",
        "max_iter = 10000\n",
        "def compute_loss_error(l1, l2):\n",
        "  return np.abs(l1 - l2)/np.max([l1,l2])\n",
        "\n",
        "def loss_f(in_pos):\n",
        "  y = in_pos.pow(6).sum() + offset\n",
        "  return y\n",
        "  \n",
        "device = torch.device(accelerator)\n",
        "np.random.seed(0)\n",
        "N = 4\n",
        "x1 = Variable(torch.Tensor(std_val * (np.random.randn(1,N) + mean_val),device=device).double(),requires_grad = True)\n",
        "y = loss_f(x1)\n",
        "\n",
        "pprint(y.data.numpy())\n",
        "#Optimize Using Gradient Descent\n",
        "learning_rate = .001\n",
        "i = 1\n",
        "last_loss = loss_f(x1).data.numpy()[0]\n",
        "adj_error = last_loss\n",
        "while i<=max_iter and adj_error > iter_stop:\n",
        "  \n",
        "  loss = loss_f(x1)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    x1 -= learning_rate * x1.grad\n",
        "    x1.grad.zero_()\n",
        "  if i % 10 == 0:  \n",
        "    curr_loss = loss_f(x1).data.numpy()[0]\n",
        "    adj_error = compute_loss_error(last_loss,curr_loss)\n",
        "    last_loss = curr_loss\n",
        "  i = i + 1\n",
        "    \n",
        "print(\"Iteration \" + str(i))\n",
        "print(\"Approx location\")\n",
        "print(x1.data.numpy()[0])\n",
        "pprint(\"Approx Value\")\n",
        "pprint(loss_f(x1).data.numpy()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zdFvE0UpzvuH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice that this blew up with the SGD optimizer, but this is fairly typical of many problems.  SGD works well when the starting point is close to the target and when the problem is quadratic, but doesn't work particularily well in many other cases.  The user can run experiments with the learning_rate to improve performance, but the improvements do not happen very fast."
      ]
    },
    {
      "metadata": {
        "id": "aE9dl-Po53ng",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Adam"
      ]
    },
    {
      "metadata": {
        "id": "X6YLrUkTXdk9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define setup\n",
        "from torch.autograd import Variable\n",
        "offset = Variable(torch.Tensor([4.]).double(), requires_grad = False)\n",
        "mean_val = 2.\n",
        "std_val = 2.\n",
        "iter_stop = 1e-7\n",
        "max_iter = 10000\n",
        "def compute_loss_error(l1, l2):\n",
        "  return np.abs(l1 - l2)/np.max([l1,l2])\n",
        "\n",
        "def loss_f(in_pos, target):\n",
        "  y = in_pos.pow(6).sum() + offset\n",
        "  return y\n",
        "  \n",
        "device = torch.device(accelerator)\n",
        "N = 4\n",
        "np.random.seed(0)\n",
        "x1 = Variable(torch.Tensor(std_val * (np.random.randn(1,N) + mean_val),device=device).double(),requires_grad = True)\n",
        "y = loss_f(x1,0.0)\n",
        "#define optimizer\n",
        "optimizer = torch.optim.Adam([x1], lr=.04, betas=(.5,.9))\n",
        "#Optimize\n",
        "i = 1\n",
        "last_loss = loss_f(x1,0.0).data.numpy()[0]\n",
        "adj_error = last_loss\n",
        "while i<=max_iter and adj_error > iter_stop:\n",
        "  optimizer.zero_grad()\n",
        "  loss = loss_f(x1, 0.0)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if i % 10 == 0:  \n",
        "    curr_loss = loss_f(x1,0.0).data.numpy()[0]\n",
        "    adj_error = compute_loss_error(last_loss,curr_loss)\n",
        "    last_loss = curr_loss\n",
        "  i = i + 1\n",
        "    \n",
        "print(\"Iteration \" + str(i))\n",
        "print(\"Approx location\")\n",
        "print(x1.data.numpy()[0])\n",
        "pprint(\"Approx Value\")\n",
        "pprint(loss_f(x1,0.0).data.numpy()[0])\n",
        "print('max relative difference')\n",
        "pprint(np.abs(x1.data.numpy()[0][0] - x1.data.numpy()[0][1])/np.min(np.abs(x1.data.numpy()[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yXUyBFO43ppT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Adam optimizer is more robust for finding solutions rather than exploding or developing vanishing gradients.  There are always other optimizers to learn, but the use of the momentum factors improves the robutness of the convergence.  One item that is beginning to get notice is the type of solution with Adam, namely, in this simple case the maximum relative difference is much higher than with the SGD.\n",
        "\n",
        "There is some thought that this might lead to less \"generalized\" solutions in some problems."
      ]
    },
    {
      "metadata": {
        "id": "xKDg96CE59Fv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Adam with Multiple Optimizers"
      ]
    },
    {
      "metadata": {
        "id": "uJp0ZMcl6Eon",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "On complex problems, it has been observed that changing the betas as you get closer to a solution often leads to faster convergence.  In the next two cells, notice that even on our simple problems and using very simple criteria to change the optimizers we do achieve faster convergence.  pytorch is particularily easy to use in this regard since the compute graphs are dynamically computed.  <b>(This is a potentially strong feature for pytorch.)</b>"
      ]
    },
    {
      "metadata": {
        "id": "T_Zqs6OxxIwB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9b533e85-bc5c-4fb1-e060-ce35d42faaba"
      },
      "cell_type": "code",
      "source": [
        "#define setup\n",
        "from torch.autograd import Variable\n",
        "offset = Variable(torch.Tensor([4.]).double(), requires_grad = False)\n",
        "mean_val = 2.\n",
        "std_val = 2.\n",
        "iter_stop = 1e-7\n",
        "max_iter = 10000\n",
        "def compute_loss_error(l1, l2):\n",
        "  return np.abs(l1 - l2)/np.max([l1,l2])\n",
        "\n",
        "def loss_f(in_pos, target):\n",
        "  y = in_pos.pow(6).sum() + offset\n",
        "  return y\n",
        "  \n",
        "device = torch.device(accelerator)\n",
        "N = 4\n",
        "np.random.seed(0)\n",
        "x1 = Variable(torch.Tensor(std_val * (np.random.randn(1,N) + mean_val),device=device).double(),requires_grad = True)\n",
        "y = loss_f(x1,0.0)\n",
        "#define optimizer\n",
        "optimizer = torch.optim.Adam([x1], lr=.04, betas=(.5,.9))\n",
        "optimizer2 = torch.optim.Adam([x1], lr=.04, betas=(.9,.95))\n",
        "optimizer3 = torch.optim.Adam([x1], lr=.04, betas=(.9,.999))\n",
        "#Optimize\n",
        "i = 1\n",
        "last_loss = loss_f(x1,0.0).data.numpy()[0]\n",
        "adj_error = last_loss\n",
        "while i<=max_iter and adj_error > iter_stop:\n",
        "  if adj_error > .1:\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_f(x1, 0.0)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  else:\n",
        "    optimizer2.zero_grad()\n",
        "    loss = loss_f(x1, 0.0)\n",
        "    loss.backward()\n",
        "    optimizer2.step()   \n",
        "  if i % 10 == 0:  \n",
        "    curr_loss = loss_f(x1,0.0).data.numpy()[0]\n",
        "    adj_error = compute_loss_error(last_loss,curr_loss)\n",
        "    last_loss = curr_loss\n",
        "  i = i + 1\n",
        "    \n",
        "print(\"Iteration \" + str(i))\n",
        "print(\"Approx location\")\n",
        "print(x1.data.numpy()[0])\n",
        "pprint(\"Approx Value\")\n",
        "pprint(loss_f(x1,0.0).data.numpy()[0])\n",
        "print('max relative difference')\n",
        "pprint(np.abs(x1.data.numpy()[0][0] - x1.data.numpy()[0][1])/np.min(np.abs(x1.data.numpy()[0])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 381\n",
            "Approx location\n",
            "[-0.02688861  0.0072186  -0.0576078   0.09676172]\n",
            "'Approx Value'\n",
            "4.0000008576979225\n",
            "max relative difference\n",
            "4.724905117913807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dL4bXonzv0uk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define setup\n",
        "from torch.autograd import Variable\n",
        "offset = Variable(torch.Tensor([4.]).double(), requires_grad = False)\n",
        "mean_val = 2.\n",
        "std_val = 2.\n",
        "iter_stop = 1e-7\n",
        "max_iter = 10000\n",
        "def compute_loss_error(l1, l2):\n",
        "  return np.abs(l1 - l2)/np.max([l1,l2])\n",
        "\n",
        "def loss_f(in_pos):\n",
        "  y = in_pos.pow(6).sum() + offset\n",
        "  return y\n",
        "  \n",
        "device = torch.device(accelerator)\n",
        "N = 4\n",
        "np.random.seed(0)\n",
        "x1 = Variable(torch.Tensor(std_val * (np.random.randn(1,N) + mean_val),device=device).double(),requires_grad = True)\n",
        "y = loss_f(x1)\n",
        "#define optimizer\n",
        "optimizer = torch.optim.Adam([x1], lr=.04, betas=(.5,.9))\n",
        "optimizer2 = torch.optim.Adam([x1], lr=.04, betas=(.9,.95))\n",
        "optimizer3 = torch.optim.Adam([x1], lr=.04, betas=(.9,.999))\n",
        "#Optimize\n",
        "i = 1\n",
        "last_loss = loss_f(x1).data.numpy()[0]\n",
        "adj_error = last_loss\n",
        "while i<=max_iter and adj_error > iter_stop:\n",
        "  if adj_error > .1:\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_f(x1)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  elif adj_error > .01:\n",
        "    optimizer2.zero_grad()\n",
        "    loss = loss_f(x1)\n",
        "    loss.backward()\n",
        "    optimizer2.step()\n",
        "  else:\n",
        "    optimizer3.zero_grad()\n",
        "    loss = loss_f(x1)\n",
        "    loss.backward()\n",
        "    optimizer3.step()    \n",
        "  if i % 10 == 0:  \n",
        "    curr_loss = loss_f(x1).data.numpy()[0]\n",
        "    adj_error = compute_loss_error(last_loss,curr_loss)\n",
        "    last_loss = curr_loss\n",
        "  i = i + 1\n",
        "    \n",
        "print(\"Iteration \" + str(i))\n",
        "print(\"Approx location\")\n",
        "print(x1.data.numpy()[0])\n",
        "pprint(\"Approx Value\")\n",
        "pprint(loss_f(x1).data.numpy()[0])\n",
        "print('max relative difference')\n",
        "pprint(np.abs(x1.data.numpy()[0][0] - x1.data.numpy()[0][1])/np.min(np.abs(x1.data.numpy()[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "25pUChA-6bzw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "On this simple problem, the choice of different optimizers at different steps yielded a 28.5% performance improvement.  This is certainly something to consider when training long running NN.  It should be noted that the maximum relative difference in these tests are still fairly high compared to the initlal tests with SGD."
      ]
    },
    {
      "metadata": {
        "id": "euPaeLCn8CAY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  Using Multiple Optimizers with a Finish Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "9VrrN44z8fCy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As discussed in [Improving Generalization Performance by Switching from Adam to SGD](https://arxiv.org/abs/1712.07628), it might be possible to improve stability by using Adam (or variants early) then switching to SGD (or variants later).  The next cell demonstrates this possibility for our simple problem.  The convergence isn't as fast as using Adam, but the resulting solution is smoother as seen in the original problem.  This is certainly worth considering."
      ]
    },
    {
      "metadata": {
        "id": "unu9AMwl0r9N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define setup\n",
        "from torch.autograd import Variable\n",
        "offset = Variable(torch.Tensor([4.]).double(), requires_grad = False)\n",
        "mean_val = 2.\n",
        "std_val = 2.\n",
        "iter_stop = 1e-7\n",
        "max_iter = 10000\n",
        "def compute_loss_error(l1, l2):\n",
        "  return np.abs(l1 - l2)/np.max([l1,l2])\n",
        "\n",
        "def loss_f(in_pos, target):\n",
        "  y = in_pos.pow(6).sum() + offset\n",
        "  return y\n",
        "  \n",
        "device = torch.device(accelerator)\n",
        "N = 4\n",
        "np.random.seed(0)\n",
        "x1 = Variable(torch.Tensor(std_val * (np.random.randn(1,N) + mean_val),device=device).double(),requires_grad = True)\n",
        "y = loss_f(x1,0.0)\n",
        "#define optimizer\n",
        "optimizer = torch.optim.Adam([x1], lr=.04, betas=(.5,.9))\n",
        "optimizer2 = torch.optim.SGD([x1], lr=.1)\n",
        "#Optimize\n",
        "i = 1\n",
        "last_loss = loss_f(x1,0.0).data.numpy()[0]\n",
        "adj_error = last_loss\n",
        "while i<=max_iter and adj_error > iter_stop:\n",
        "  if adj_error > .1:\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_f(x1, 0.0)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  else:\n",
        "    optimizer2.zero_grad()\n",
        "    loss = loss_f(x1, 0.0)\n",
        "    loss.backward()\n",
        "    optimizer2.step()   \n",
        "  if i % 10 == 0:  \n",
        "    curr_loss = loss_f(x1,0.0).data.numpy()[0]\n",
        "    adj_error = compute_loss_error(last_loss,curr_loss)\n",
        "    last_loss = curr_loss\n",
        "  i = i + 1\n",
        "    \n",
        "print(\"Iteration \" + str(i))\n",
        "print(\"Approx location\")\n",
        "print(x1.data.numpy()[0])\n",
        "pprint(\"Approx Value\")\n",
        "pprint(loss_f(x1,0.0).data.numpy()[0])\n",
        "print('max relative difference')\n",
        "pprint(np.abs(x1.data.numpy()[0][0] - x1.data.numpy()[0][1])/np.min(np.abs(x1.data.numpy()[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5lxhIy6D-GxI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ]
    },
    {
      "metadata": {
        "id": "CwnKVxGz-LQx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It is comforting to see that the optimization methods in DL are variations on mathematical convex optimizations; futhermore, the entire optimization environment has a lot of flexibility for solving problems.  This is probably as good as any environment for working with larger and more complex problems since you don't have to do much of the gradient computation manually."
      ]
    }
  ]
}